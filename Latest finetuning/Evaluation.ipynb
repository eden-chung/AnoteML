{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f48b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93889c86",
   "metadata": {},
   "source": [
    "### Functions to create knowledge hub (You do not need to edit this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca63217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7be42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key= OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df6fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_hub(path_to_10k):\n",
    "    \"\"\"From a 10-K document, create a Chroma DB knowledge hub.\n",
    "\n",
    "    Args:\n",
    "        path_to_10k: Relative path to the 10-K hosted locally on the user's computer\n",
    "\n",
    "    Returns:\n",
    "        vectordb: The vector database with the information from the 10-K\n",
    "        db_directory: The path to the vector database\n",
    "    \"\"\"\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    db_directory = \"db_\" + timestamp\n",
    "\n",
    "    loader = PyPDFLoader(path_to_10k)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=5,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        length_function=len)\n",
    "    texts = splitter.split_documents(documents)\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=texts, \n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_directory\n",
    "    )\n",
    "    vectordb.persist()\n",
    "\n",
    "    return vectordb, db_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0cbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_chroma_db(db_directory):\n",
    "    \"\"\"Deletes the Chroma DB created locally on the computer\n",
    "\n",
    "    Args:\n",
    "        db_directory: The path to the vector database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shutil.rmtree(db_directory)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Chroma database '{db_directory}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting Chroma database: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1779681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_strings(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([text1, text2])\n",
    "    # Calculate the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b783d",
   "metadata": {},
   "source": [
    "### Function to query model. Change this part with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1c0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(path_to_10k, question):\n",
    "    \"\"\"Ask the fine-tuned GPT model a question based off a local 10-K document.\n",
    "\n",
    "    Args:\n",
    "        path_to_10k: Relative path to the 10-K hosted locally on the user's computer\n",
    "        question: Question to ask the model\n",
    "\n",
    "    Returns:\n",
    "        answer: The answer given by the fine-tuned GPT model\n",
    "    \"\"\"\n",
    "\n",
    "    db, db_dir = create_knowledge_hub(path_to_10k)\n",
    "\n",
    "    source1 = db.similarity_search(question, k = 2)[0].page_content\n",
    "    source2 = db.similarity_search(question, k = 2)[1].page_content\n",
    "\n",
    "    ## EDIT THIS PART\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a factual chatbot that answers questions about 10-K documents. You only answer with answers you find in the text, no outside information.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{source1}{source2} Now, this is our question: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "    ## END OF EDITING\n",
    "\n",
    "    delete_chroma_db(db_dir)\n",
    "    \n",
    "    answer = completion.choices[0].message.content #You might have to edit this\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model. Run this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbe2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv_dataset = \"Datasets/financebench_sample_150.csv\" ##Replace this with the path to your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa41c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"download.pdf\"\n",
    "\n",
    "def download_document(url):\n",
    "    \"\"\"Download a PDF based off a URL\n",
    "\n",
    "    Args:\n",
    "        url: URL to the document found online\n",
    "\n",
    "    Returns:\n",
    "        filename: the filename on your computer\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return filename\n",
    "\n",
    "def delete_document(file_path):\n",
    "    \"\"\"Delete a document at a given file path.\n",
    "\n",
    "    Args:\n",
    "        file_path: The full file path of the document to be deleted.\n",
    "    \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted file: {file_path}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b86c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(path_to_csv_dataset):\n",
    "    list_of_cosine_similarity = []\n",
    "\n",
    "    df = pd.read_csv(path_to_csv_dataset)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        doc_link = row['doc_link']\n",
    "\n",
    "        #download the document from URL given\n",
    "        download_document(doc_link)\n",
    "\n",
    "        #query our model\n",
    "        model_answer = query_model(filename, question)\n",
    "\n",
    "        #compare similarity\n",
    "        sim = compare_strings(answer, model_answer)\n",
    "\n",
    "        print(\"answers are\", answer, model_answer)\n",
    "\n",
    "        print(\"sim is\", sim)\n",
    "\n",
    "        #delete the document downloaded\n",
    "        delete_document(filename)\n",
    "\n",
    "        #add the similarity to the list\n",
    "        list_of_cosine_similarity.append(sim)\n",
    "\n",
    "    #get the average of the similarities\n",
    "    return sum(list_of_cosine_similarity) / len(list_of_cosine_similarity) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers are $1,577.00  The FY2018 capital expenditure amount for 3M was not provided in the given information.\n",
      "sim is 0.0\n",
      "Deleted file: download.pdf\n",
      "answers are $8.70  Based on the information provided, the net PP&E (Property, Plant, and Equipment) for 3M at the year end of FY2018 was not explicitly stated in the text. Therefore, I cannot provide the specific value in USD billions.\n",
      "sim is 0.0\n",
      "Deleted file: download.pdf\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#This should be your final answer for your model's accuracy\n",
    "print(run_eval(path_to_csv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
